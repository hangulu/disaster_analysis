---
title: 'Unnatural Disasters Data Cleaning: Storm Data'
author: "Hakeem Angulu and Louie Ayre"
date: "12/8/2018"
output: 
  pdf_document:
    fig_height: 3.5
    fig_width: 5
    highlight: pygments
    keep_tex: yes
    latex_engine: xelatex
fontsize: 10pt
mainfont: Gotham
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r lib}
# Load libraries
library(dplyr)
library(tidyverse)
```


## Storms Data

```{r test.1 eval=F}
# Before 1955, the only storms are tornadoes
storms2016 = full_clean("./data/storms/storms2016.csv")
```

```{r test.2 eval=F}
test = collapse_storms(storms2016)
```


```{r storms.1}
clean_storm <- function(file_path) {
  # Read in the data
  data <- read.csv(file_path)
  
  # Add the indirect to the direct
  data$INJURIES <- data$INJURIES_DIRECT + data$INJURIES_INDIRECT
  data$DEATHS <- data$DEATHS_DIRECT + data$DEATHS_INDIRECT
  
  # Transform property damage to a number
  data$DAMAGE_K <- as.numeric(sub("K", "e3", data$DAMAGE_PROPERTY, fixed = TRUE))
  data$DAMAGE_M <- as.numeric(sub("M", "e6", data$DAMAGE_PROPERTY, fixed = TRUE))
  
  # Combine the millions and thousands of damage from above into one column
  data$DAMAGE <- ifelse(is.na(data$DAMAGE_K), data$DAMAGE_M, data$DAMAGE_K)
  
  # NAs at this point are for missing data, assumed to be 0. Fix that
  data$DAMAGE[is.na(data$DAMAGE)] <- 0
  
  # Only keep columns of interest
  keep = c("YEAR", "STATE", "EVENT_TYPE", "INJURIES", "DEATHS", "DAMAGE")
  data <- subset(data, select = keep)
  
  return(data)
}
```

```{r storms.2}
agg_storm <- function(df) {
  # Use the dplyr package to group by state and event type, then fold the calculations to summarize
  tidied <- df %>%
  group_by(STATE, EVENT_TYPE, YEAR) %>%
  summarise(injured = sum(INJURIES),
            deaths = sum(DEATHS),
            damage = sum(DAMAGE))
  # Rename the columns
  names(tidied) <- c("state", "storm_type", "year", "injured", "deaths", "property_damage")
  return(tidied)
}
```

```{r storms.3}
# Function to reduce the number of types of storms. The following are the reductions:
# windstorm: Tornado, High Wind, Marine High Wind, Marine Strong Wind,
#            Marine Thunderstorm Wind
# snowstorm: Avalanche, Blizzard, Frost/Freeze, Hail, Heavy Snow, Ice Storm, 
#            Lake-Effect Snow, Marine Hail, Sleet, Winter Weather, Winter Storm
# rainstorm: Coastal Flood, Flash Flood, Flood, Heavy Rain, Hurricane (Typhoon), 
#            Lakeshore Flood, Rip Current, Tsunami, Tropical Depression,
#            Tropical Storm
# heatstorm: Wildfire, Drought, Excessive Heat
collapse_storms <- function(df) {
  # Use the dplyr package to group by state, then reassign the event type
  windstorm = c("Tornado", "High Wind", "Marine High Wind", "Marine Strong Wind", "Marine Thunderstorm Wind")
  snowstorm = c("Avalanche", "Blizzard", "Frost/Freeze", "Hail", "Heavy Snow", "Ice Storm", "Lake-Effect Snow", "Marine Hail", "Sleet", "Winter Weather", "Winter Storm")
  rainstorm = c("Coastal Flood", "Flash Flood", "Flood", "Heavy Rain", "Hurricane (Typhoon)", "Lakeshore Flood", "Rip Current", "Tsunami", "Tropical Depression", "Tropical Storm")
  heatstorm = c("Wildfire", "Drought", "Excessive Heat")
  df <- df %>% 
    group_by(state) %>% 
    mutate(storm_type = case_when(storm_type %in% windstorm ~ "windstorm", 
                                  storm_type %in% snowstorm ~ "snowstorm",
                                  storm_type %in% rainstorm ~ "rainstorm",
                                  storm_type %in% heatstorm ~ "heatstorm"))
  
  # Remove the NAs (storms that had no meaningful/useful classfication)
  df <- drop_na(df)

  # Use the aggregate function to aggregate by state and storm_type
  agg <- aggregate(. ~ state + storm_type + year, df, sum)
  
  return(agg)
}

# A wrapper for the three functions
full_clean <- function(file_path) {
  return(collapse_storms(agg_storm(clean_storm(file_path))))
}
```

```{r}
# Store the data as one long CSV
files <- list.files(path="/Users/hakeemangulu/Code/disaster_analysis/data/storms", full.names=TRUE, recursive=FALSE)
full_set = full_clean("/Users/hakeemangulu/Code/disaster_analysis/data/storms/storms1955.csv")
for(i in 1:length(files)){
  full_set <- rbind(full_set, full_clean(files[i]))
}
write.csv(full_set, "/Users/hakeemangulu/Code/disaster_analysis/data/storms/storm_data.csv")
```

## Include Predictors

```{r storms.1}
# Set the working directory
setwd("/Users/hakeemangulu/Code/disaster_analysis/data/storms")

# Read in the CSV
storms = read.csv("storm_data.csv")

# Put the states into regions
storms$region <- NA
cali = c("CALIFORNIA")
northeast = c("CONNECTICUT", "MAINE", "MASSACHUSSETTS", "NEW HAMPSHIRE", "RHODE ISLAND", "VERMONT", "NEW JERSEY", "NEW YORK", "PENNSYLVANIA", "DELAWARE", "MARYLAND", "DISTRICT OF COLUMBIA")
midwest = c("ILLINOIS", "INDIANA", "IOWA", "KANSAS", "MICHIGAN", "MINNESOTA", "MISSOURI", "NEBRASKA", "NORTH DAKOTA", "OHIO", "SOUTH DAKOTA", "WISCONSIN")
south = c("FLORIDA", "GEORGIA", "NORTH CAROLINA", "SOUTH CAROLINA", "VIRGINIA", "WEST VIRGINIA", "ALABAMA", "KENTUCKY", "MISSISSIPPI", "TENNESSEE", "ARKANSAS", "LOUISIANA", "OKLAHOMA", "TEXAS")
df <- storms %>% 
    group_by(state) %>% 
    mutate(region = case_when(state %in% cali ~ "california", 
                                  state %in% northeast ~ "northeast",
                                  state %in% midwest ~ "midwest",
                                  state %in% south ~ "south"))

# Remove the NAs (states that we are not analyzing)
df <- drop_na(df)

# Use the dplyr package to group by state and event type, then fold the calculations to summarize
tidied <- df %>%
group_by(region, storm_type, year) %>%
summarise(injured = sum(injured),
            deaths = sum(deaths),
            damage = sum(property_damage))

```

```{r}
# Separate the storms by region and remove observations before 1980
california_storms = subset(tidied, region == "california" & storm_type == "heatstorm" & year >= 1980)
northeast_storms = subset(tidied, region == "northeast" & storm_type == "snowstorm" & year >= 1980)
midwest_storms = subset(tidied, region == "midwest" & storm_type == "windstorm" & year >= 1980)
south_storms = subset(tidied, region == "south" & storm_type == "rainstorm" & year >= 1980)
```

```{r}
# Load and clean industrial emissions
indu <- read.csv("/Users/hakeemangulu/Code/disaster_analysis/data/emissions/industrial_CO2_emissions.csv")

# Group the states
north_list <- c("Connecticut", "Maine", "Massachussets", "New Hampshire", "Rhode Island", "Vermont", "New Jersey", "New York", "Pennsylvania", "Delaware", "Maryland", "District of Columbia")
midwest_list <- c("Illinois", "Indiana", "Iowa", "Kansas", "Michigan", "Minnesota", "Missouri", "Nebraska", "North Dakota", "Ohio", "South Dakota", "Wisconsin")
south_list <- c("Florida", "Georgia", "North Carolina", "South Carolina", "Virginia", "West Virginia", "Alabama", "Kentucky", "Mississippi", "Tennessee", "Arkansas", "Louisiana", "Oklahoma", "Texas")
indu$region <- NA
df <- indu %>% 
    group_by(State) %>% 
    mutate(region = case_when(State == "California" ~ "california", 
                              State %in% north_list ~ "northeast",
                              State %in% midwest_list ~ "midwest",
                              State %in% south_list ~ "south"))

# Remove the NAs (states that we are not analyzing)
df <- subset(df, !is.na(df$region))
df$State <- NULL
df$X.1 <- NULL
df$X.2 <- NULL
df$X <- NULL

# Use the aggregate function to aggregate by region and storm_type
agg <- aggregate(. ~ region, df, sum)

california_storms$indu_emis <- t(agg[agg$region == "california",18:38])
northeast_storms$indu_emis <- t(agg[agg$region == "northeast", 2:38])
midwest_storms$indu_emis <- t(agg[agg$region == "midwest", 2:38])
south_storms$indu_emis <- t(agg[agg$region == "south", 18:38])
```

```{r}
# Load and clean energy
energy <- read.csv("/Users/hakeemangulu/Code/disaster_analysis/data/energy_usage/energy_production.csv")

# Get total energy production and renewable energy production

# Group the states
north_list_short <- c("CT", "ME", "MA", "NH", "RI", "VT", "NJ", "NY", "PA", "DE", "MD", "DC")
midwest_list_short <- c("IL", "IN", "IA", "KS", "MI", "MN", "MO", "NE", "ND", "OH", "SD", "WI")
south_list_short <- c("FL", "GA", "NC", "SC", "VA", "WV", "AL", "KY", "MS", "TN", "AK", "LA", "OK", "TX")

energy$region <- NA
df <- energy %>% 
    group_by(StateCode) %>% 
    mutate(region = case_when(StateCode == "CA" ~ "california", 
                              StateCode %in% north_list_short ~ "northeast",
                              StateCode %in% midwest_list_short ~ "midwest",
                              StateCode %in% south_list_short ~ "south"))

# Remove the NAs (states that we are not analyzing)
df <- subset(df, !is.na(df$region))

df <- subset(df, df$MSN == "TEPRB" | df$MSN == "REPRB")
df$Data_Status <- NULL
df$StateCode <- NULL

# Use the aggregate function to aggregate by region and MSN (energy source)
agg2 <- aggregate(. ~ region + MSN, df, sum)

# Separate the energy sources
repr_agg <- subset(agg2, agg2$MSN == "REPRB")
repr_agg$MSN <- NULL
tepr_agg <- subset(agg2, agg2$MSN == "TEPRB")
tepr_agg$MSN <- NULL

california_storms$total_energy_prod <- t(tepr_agg[tepr_agg$region == "california",38:58])
california_storms$renew_energy_prod <- t(repr_agg[repr_agg$region == "california",38:58])

northeast_storms$total_energy_prod <- t(tepr_agg[tepr_agg$region == "northeast",22:58])
northeast_storms$renew_energy_prod <- t(repr_agg[repr_agg$region == "northeast",22:58])

midwest_storms$total_energy_prod <- t(tepr_agg[tepr_agg$region == "midwest",22:58])
midwest_storms$renew_energy_prod <- t(repr_agg[repr_agg$region == "midwest",22:58])

south_storms$total_energy_prod <- t(tepr_agg[tepr_agg$region == "south",38:58])
south_storms$renew_energy_prod <- t(repr_agg[repr_agg$region == "south",38:58])

# Get non-renewable enrgy production
california_storms$nonrenew_energy_prod <- california_storms$total_energy_prod - california_storms$renew_energy_prod
northeast_storms$nonrenew_energy_prod <- northeast_storms$total_energy_prod - northeast_storms$renew_energy_prod
midwest_storms$nonrenew_energy_prod <- midwest_storms$total_energy_prod - midwest_storms$renew_energy_prod
south_storms$nonrenew_energy_prod <- south_storms$total_energy_prod - south_storms$renew_energy_prod
```


```{r}
# Load CO2 concentration
co2 <- read.csv("/Users/hakeemangulu/Code/disaster_analysis/data/emissions/co2_concentration.csv")
abbrev_co2 = subset(co2, co2$year >= 1996)
california_storms$co2_conc <- abbrev_co2[,2]
northeast_storms$co2_conc <- co2[,2]
midwest_storms$co2_conc <- co2[,2]
south_storms$co2_conc <- abbrev_co2[,2]

# Load methane concetration
meth <- read.csv("/Users/hakeemangulu/Code/disaster_analysis/data/emissions/methane_concetration.csv")
abbrev_meth = subset(meth, meth$year >= 1996)
california_storms$meth_conc <- abbrev_meth[,2]
northeast_storms$meth_conc <- meth[,2]
midwest_storms$meth_conc <- meth[,2]
south_storms$meth_conc <- abbrev_meth[,2]
```

```{r}
# Load CSVs coal emissions, and petroleum CO2 emissions
coal <- read.csv("/Users/hakeemangulu/Code/disaster_analysis/data/emissions/coal_emissions.csv")
jelly <- read.csv("/Users/hakeemangulu/Code/disaster_analysis/data/emissions/petroleum_CO2_emissions.csv")

# Coal
# Group the states
coal$region <- NA
df <- coal %>% 
    group_by(State) %>% 
    mutate(region = case_when(State == "California" ~ "california", 
                              State %in% north_list ~ "northeast",
                              State %in% midwest_list ~ "midwest",
                              State %in% south_list ~ "south"))

# Remove the NAs (states that we are not analyzing)
df <- subset(df, !is.na(df$region))
df$State <- NULL
df$Percent <- NULL
df$Absolute <- NULL
df$X41 <- NULL
df$X <- NULL

# Use the aggregate function to aggregate by region and storm_type
agg <- aggregate(. ~ region, df, sum)

california_storms$coal_emis <- t(agg[agg$region == "california",18:38])
northeast_storms$coal_emis <- t(agg[agg$region == "northeast", 2:38])
midwest_storms$coal_emis <- t(agg[agg$region == "midwest", 2:38])
south_storms$coal_emis <- t(agg[agg$region == "south", 18:38])

# Petroleum
# Group the states
jelly$region <- NA
df <- jelly %>% 
    group_by(State) %>% 
    mutate(region = case_when(State == "California" ~ "california", 
                              State %in% north_list ~ "northeast",
                              State %in% midwest_list ~ "midwest",
                              State %in% south_list ~ "south"))

# Remove the NAs (states that we are not analyzing)
df <- subset(df, !is.na(df$region))
df$State <- NULL
df$Percent <- NULL
df$Absolute <- NULL
df$X41 <- NULL
df$X <- NULL

# Use the aggregate function to aggregate by region and storm_type
agg <- aggregate(. ~ region, df, sum)

california_storms$petrol_emis <- t(agg[agg$region == "california",18:38])
northeast_storms$petrol_emis <- t(agg[agg$region == "northeast", 2:38])
midwest_storms$petrol_emis <- t(agg[agg$region == "midwest", 2:38])
south_storms$petrol_emis <- t(agg[agg$region == "south", 18:38])
```

```{r}
write.csv(california_storms, "/Users/hakeemangulu/Code/disaster_analysis/data/cleaned/california_storms.csv")
write.csv(northeast_storms, "/Users/hakeemangulu/Code/disaster_analysis/data/cleaned/northeast_storms.csv")
write.csv(midwest_storms, "/Users/hakeemangulu/Code/disaster_analysis/data/cleaned/midwest_storms.csv")
write.csv(south_storms, "/Users/hakeemangulu/Code/disaster_analysis/data/cleaned/south_storms.csv")
```

